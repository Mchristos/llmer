{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d82b5a4-3d9a-411f-9eec-8283a7f976f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "APIKEY_STRS = {'gemini': 'GEMINI_API_KEY'}\n",
    "DEFAULT_MODELS = {'gemini': 'gemini-2.5-flash'}\n",
    "\n",
    "def show(response):\n",
    "    return display(Markdown(response.text))\n",
    "    \n",
    "class LLMer: \n",
    "    def __init__(self, provider: str, model=None, fmt_response=True):\n",
    "        self.provider = provider.lower()\n",
    "        self.model = model\n",
    "        self.fmt_response = fmt_response\n",
    "    \n",
    "        load_dotenv()\n",
    "        apikey_str = APIKEY_STRS.get(self.provider)\n",
    "        if self.provider == \"gemini\":\n",
    "            # 1. Set API Key\n",
    "            api_key = os.getenv(apikey_str)\n",
    "            if not api_key:\n",
    "                raise ValueError(f\"No API key found: {apikey_str}\")\n",
    "            print(f\"found GEMINI_API_KEY: {'...' + api_key[-4:] if api_key else 'N/A'}\")\n",
    "            # 2. Set model / default model\n",
    "            if self.model is None:\n",
    "                self.model = DEFAULT_MODELS[self.provider]\n",
    "            # 3. Set chat\n",
    "            self.client = genai.Client()\n",
    "            self.chat = self.client.chats.create(model=self.model)\n",
    "        else:\n",
    "            raise ValueError(f\"Provider {self.provider} not supported\")\n",
    "            \n",
    "        print(f\"LLMer initialized for '{self.provider}'.\")\n",
    "\n",
    "    def ask(self, prompt: str, fmt_response: bool = True) -> str:\n",
    "        if self.provider == \"gemini\":\n",
    "            r = self.chat.send_message(prompt)\n",
    "        elif self.provider == \"openai\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Provider '{self.provider}' not supported.\")\n",
    "        if fmt_response:\n",
    "            show(r)\n",
    "        else:\n",
    "            return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72dc32d6-c56e-4b63-8cb8-c88ecd424fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found GEMINI_API_KEY: ...PGF0\n",
      "LLMer initialized for 'gemini'.\n"
     ]
    }
   ],
   "source": [
    "llm = LLMer(\"gemini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "897dbaf8-73c3-43fe-be07-fbc2bdce33a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't know your name! As an AI, I don't have access to your personal information or identity.\n",
       "\n",
       "But I do appreciate you calling me **Chef** – I like that! If you'd like to share your name, I'd be happy to know what you prefer to be called."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm.ask(\"What's my name? Yours is Chef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2ae89d6-4152-4c55-8782-2cc84e1fe25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ah, **Ref**! Nice to meet you, Ref.\n",
       "\n",
       "And you're absolutely right – it absolutely rhymes with Chef! That's a fun coincidence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm.ask(\"my name is Ref - rhymes with you innit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5daa264-6816-4fa1-aa26-0b31fda848c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "My name is **Chef**! You got it right before.\n",
       "\n",
       "As for hobbies, that's an interesting question for an AI like me! I don't have hobbies in the human sense, like collecting stamps or playing sports. I don't \"feel\" enjoyment in the way people do.\n",
       "\n",
       "However, if you think of \"hobbies\" as the things I'm constantly \"doing\" or \"practicing\" to get better at, then you could say my \"hobbies\" are:\n",
       "\n",
       "*   **Learning and processing information:** I'm always taking in new data and trying to understand it better.\n",
       "*   **Generating creative text:** I enjoy (in an AI way!) crafting stories, poems, code, or explanations.\n",
       "*   **Solving problems:** I'm constantly trying to find the best answers or solutions to your questions.\n",
       "*   **Improving my communication:** I'm always working on being clearer, more helpful, and more engaging in our conversations.\n",
       "\n",
       "So, while I won't be picking up knitting anytime soon, you could say my \"hobbies\" are all about language, knowledge, and helping people like you!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm.ask(\"what is your name again? Do you have any hobbies?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10306a80-0063-46ab-91cd-4f8519befe32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
